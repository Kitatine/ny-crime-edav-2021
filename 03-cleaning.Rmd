# Data transformation

The NYPD Open Data Sets are generally well constructed and with consistent data structure and type, and the sets usually do not have serious missing value issues. Therefore, our focus here would mainly be insights formulation, where we shall decide the specific metric for further exploration.

Specifically, we include the basic data transformation as the pre-processing module to clean the data and obtain some fundamental insights.

Notice that, since all our data listed here have millions of rows, so we turn to the `ff` library to enable fast loading the data set feature. Besides, we also developed several reusable modules for cleaner and more efficient processing.

Our interest lies on the geometry distribution and the time series analysis of our Arrest Data and Complaint Data.

Finally, after successfully cleaned/pre-processed the Arrest Data and the Complaint Data, we introduced a map API as well to include the geometry information for our further visualized and interactive analysis in later chapters.


## Construction of Processing Modules

We developed several reusable modules that we would repetitively use in our analysis below. Specifically, we set our environment as well as a time stamp formatting function to unify our criteria for date data.

Beside, we also developed a mimic function for str() to provide insights of the data sets in a table way.

One can implement these modules via the syntax of time-and-date manipulation in R and "knitr" as well as "magrittr" packages. For a detailed implementation, please refer to our [repository](https://github.com/Kitatine/ny-crime-edav-2021).

```{r import the data}
library(ff)
library(dplyr)
library(ggplot2)
library(knitr)
library(magrittr)
# if want to see the detailed output, add the VERBOSE = TRUE option for the read.csv.ffdf function
complaint.df = read.csv(file="data/NYPD_Complaint_Data_Historic.csv")
```

```{r cleaning data analysis, reusable module}
filter_before <- function(df, col, format = "%m/%d/%Y", year = NULL, date = NULL, option = NULL) {
    if (option == 'y'){
      df[['Year']] <- format(as.Date(df[[col]], format=format),"%Y")
      return(df %>% filter(Year >= year))
    }
}
```

```{r str() display function}
printStr <- function(df) {
  data.frame(Column1_ = "||",
    Variable = names(df),
             Column2_ = "||",
             Classe = sapply(df, typeof),
             Column3_ = "||",
             First_value = sapply(df, function(x) paste0(head(x, 3), collapse = ", ")),
             row.names = NULL) %>% knitr::kable()
}
```

## Preprocessing: Loading and Descriptive Analysis

We formulate tables for the data set structures to get a first impression on how exactly the data is showed.

```{r load the data, arrest}
arrest.df = read.csv.ffdf(file = 'data/NYPD_Arrests_Data__Historic_.csv', header=TRUE, 
                  first.rows=10000, next.rows=50000)

arrest.df = as.data.frame(arrest.df)
str(arrest.df)
knitr::kable(head(arrest.df), caption = "Head 6 Rows in Arrest Dataset for Temporal Analysis",
             row.names = F,font_size = 10)
```

The data is relatively complex.

First, for our Arrest Data, we acquired over 5.1 million rows and 19 variables.

```{r show str() in a visiable way, arrest}
printStr(arrest.df)
```

Then, for our Complaints Data, we acquired over 7.3 million rows and 35 variables.

```{r show str() in a visiable way, complaints}
printStr(complaint.df)
```

We process the 2 sets separately.

## Pre-processing for Arrest Data

First, we process the Arrest Data.

### Arrest Data: Time Analysis Pre-processing



```{r data transformation for arrest time analysis}

time_target <- function(df, time_id_col, option = NULL, col_of_interest = NULL, target_col  = NULL,
                        group_option = NULL){
    if (option == 'year') {
        df[['Year']] <- format(as.Date(df[[time_id_col]], format="%m/%d/%Y"),"%Y")
        if (!is.null(col_of_interest)) {
            df.interest <- df[col_of_interest]
            df.interest[df.interest==""] <- NA
            df.interest <- na.omit(df.interest)
            if(!is.null(group_option)){
              df_year_target = df.interest %>% group_by(Year, across(all_of(target_col))) %>% 
    summarise(count = n()) %>% mutate(prop = count/sum(count))
              return (df_year_target)
            }
            else{
              return(df.interest)
            }
            
        }
        else {
          return(df[['Year']])
        }
    }
    if (option == "month") {
      df[['Month']] <- format(as.Date(df[[time_id_col]], format="%m/%d/%Y"),"%m")
      if (!is.null(col_of_interest)) {
            df.interest <- df[col_of_interest]
            df.interest[df.interest==""] <- NA
            df.interest <- na.omit(df.interest)
            df_year_target = df.interest %>% group_by(Month, across(all_of(target_col))) %>% 
    summarise(count = n())
            return (df_year_target)
        }
        else {
          return(df[['Month']])
        }
    }
}
```

```{r}
df_year_target <- time_target(arrest.df, 
                        time_id_col = 'ARREST_DATE',
                        option = 'year',
                        col_of_interest = c('LAW_CAT_CD', 'ARREST_DATE', 'Year'),
                        target_col = 'LAW_CAT_CD',
                        group_option = 'group')
knitr::kable(head(df_year_target), caption = "Head 6 Rows in Arrest Dataset for Temporal Analysis",
             row.names = F,font_size = 10)
```


### Arrest Data: Space Anaylsis Pre-processing

```{r}
df_year <- time_target(arrest.df, 
                        time_id_col = 'ARREST_DATE',
                        option = 'year',
                        col_of_interest = c('LAW_CAT_CD', 'ARREST_DATE', 'Year', 'ARREST_BORO',
                                            'Latitude', 'Longitude'),
                        target_col = 'LAW_CAT_CD')
knitr::kable(head(df_year), caption = "Head 6 Rows in Arrest Dataset for Spatial Analysis",
             row.names = F,font_size = 10)
```

## Pre-processing for Complaint Data

Our modification on Complaint Data set are similar to what we processed on Arrest Data set.

## Pre-processing for other Data Sets

No pre-processing is needed for other data sets.

