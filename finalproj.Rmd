--- 
title: "NY Crime Investigation"
author: "Jingwen Bai, Qiran Li, Zheng Wu"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
--- 
title: "NY Crime Investigation"
author: "Jingwen Bai, Qiran Li, Zheng Wu"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```

# Introduction


<!--chapter:end:index.Rmd-->


# Data sources

Placeholder


## NYPD Complaints Dataset
## NYPD Arrest Dataset
## Other Data Sets
## Featured Variables

<!--chapter:end:02-data.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Data transformation

The NYPD Open Data Sets are generally well constructed and with consistent data structure and type, and the sets usually do not have serious missing value issues. Therefore, our focus here would mainly be insights formulation, where we shall decide the specific metric for further exploration.

Specifically, we include the basic data transformation as the pre-processing module to clean the data and obtain some fundamental insights.

Notice that, since all our data listed here have millions of rows, so we turn to the `ff` library to enable fast loading the data set feature. Besides, we also developed several reusable modules for cleaner and more efficient processing. For more information on 'ff' package, please check [here](https://cran.r-project.org/web/packages/ff/index.html).

Our interest lies on the geometry distribution and the time series analysis of our Arrest Data and Complaint Data.

Finally, after successfully cleaned/pre-processed the Arrest Data and the Complaint Data, we introduced a map API as well to include the geometry information for our further visualized and interactive analysis in later chapters.


## Construction of Processing Modules

We developed several reusable modules that we would repetitively use in our analysis below. Specifically, we set our environment as well as a time stamp formatting function to unify our criteria for date data.

>One can implement these modules via the syntax of time-and-date manipulation in R and "knitr" as well as "magrittr" packages.

```{r cleaning data analysis, reusable module}
filter_before <- function(df, col, format = "%m/%d/%Y", year = NULL, date = NULL, option = NULL) {
    if (option == 'y'){
      df[['Year']] <- format(as.Date(df[[col]], format=format),"%Y")
      return(df %>% filter(Year >= year))
    }
}
```

>We also developed a mimic function for str() to provide insights of the data sets in a table way.

```{r str() display function}
printStr <- function(df) {
  data.frame(Column1_ = "||",
    Variable = names(df),
             Column2_ = "||",
             Classe = sapply(df, typeof),
             Column3_ = "||",
             First_value = sapply(df, function(x) paste0(head(x, 3), collapse = ", ")),
             row.names = NULL) %>% knitr::kable()
}
```

>To formulate proper data structure and columns, we developed a function allowing we derive year and/or month information from the original time stamp column of Arrest Data. Further more, this function also allow us to decide whether an grouping by year and/or month is needed. One can find further details in our repository.

```{r data transformation for arrest time analysis}

time_target <- function(df, time_id_col, option = NULL, col_of_interest = NULL, target_col  = NULL,
                        group_option = NULL){
    if (option == 'year') {
        df[['Year']] <- format(as.Date(df[[time_id_col]], format="%m/%d/%Y"),"%Y")
        if (!is.null(col_of_interest)) {
            df.interest <- df[col_of_interest]
            df.interest[df.interest==""] <- NA
            df.interest <- na.omit(df.interest)
            if(!is.null(group_option)){
              df_year_target = df.interest %>% group_by(Year, across(all_of(target_col))) %>% 
    summarise(count = n()) %>% mutate(prop = count/sum(count))
              return (df_year_target)
            }
            else{
              return(df.interest)
            }
        }
        else {
          return(df[['Year']])
        }
    }
    if (option == "month") {
      df[['Month']] <- format(as.Date(df[[time_id_col]], format="%m/%d/%Y"),"%m")
      if (!is.null(col_of_interest)) {
            df.interest <- df[col_of_interest]
            df.interest[df.interest==""] <- NA
            df.interest <- na.omit(df.interest)
            df_year_target = df.interest %>% group_by(Month, across(all_of(target_col))) %>% 
    summarise(count = n())
            return (df_year_target)
        }
        else {
          return(df[['Month']])
        }
    }
}
```

For a detailed implementation, please refer to our [repository](https://github.com/Kitatine/ny-crime-edav-2021).

## Preprocessing: Loading and Descriptive Analysis

```{r import the data}
library(ff)
library(dplyr)
library(ggplot2)
library(knitr)
library(magrittr)
# if want to see the detailed output, add the VERBOSE = TRUE option for the read.csv.ffdf function
complaint.df = read.csv(file="data/NYPD_Complaint_Data_Historic.csv")
```

We created tables for the data set structures to get a first impression on how exactly the data is showed.

```{r load the data, arrest}
arrest.df = read.csv.ffdf(file = 'data/NYPD_Arrests_Data__Historic_.csv', header=TRUE, 
                  first.rows=10000, next.rows=50000)

arrest.df = as.data.frame(arrest.df)
str(arrest.df)
knitr::kable(head(arrest.df), caption = "Head 6 Rows in Arrest Dataset for Temporal Analysis",
             row.names = F,font_size = 10)
```

The data is relatively complex.

First, for our Arrest Data, we acquired over 5.1 million rows and 19 variables.

```{r show str() in a visiable way, arrest}
printStr(arrest.df)
```

Then, for our Complaints Data, we acquired over 7.3 million rows and 35 variables.

```{r show str() in a visiable way, complaints}
printStr(complaint.df)
```

We processed the Arrest Data, Complaints Data and other data sets separately.

## Pre-processing for Arrest Data
### Arrest Data: Time Analysis Pre-processing

To formulate proper data structure and columns, we developed a function allowing we derive year and/or month information from the original time stamp column of Arrest Data. Further more, this function also allow us to decide whether an grouping by year and/or month is needed. One can find further details in our repository.

```{r}
df_year_target <- time_target(arrest.df, 
                        time_id_col = 'ARREST_DATE',
                        option = 'year',
                        col_of_interest = c('LAW_CAT_CD', 'ARREST_DATE', 'Year'),
                        target_col = 'LAW_CAT_CD',
                        group_option = 'group')
knitr::kable(head(df_year_target), caption = "Head 6 Rows in Arrest Dataset for Temporal Analysis",
             row.names = F,font_size = 10)
```

We selected information from year, LAW_CAT_CD (crime category), counting of each category, and probability represented by frequency out via processing on 'LAW_CAT_CD', 'ARREST_DATE', and 'Year'. This allowed us to perform a analysis on crime category based on their counting and probability in a time series manner.

```{r}
printStr(df_year_target)
```


### Arrest Data: Geometry Anaylsis Pre-processing

We selected out 'LAW_CAT_CD', 'ARREST_DATE', 'Year', 'ARREST_BORO', 'Latitude', and 'Longitude' in order to get a better understanding on the geometry distribution of the crimes.

```{r}
df_year <- time_target(arrest.df, 
                        time_id_col = 'ARREST_DATE',
                        option = 'year',
                        col_of_interest = c('LAW_CAT_CD', 'ARREST_DATE', 'Year', 'ARREST_BORO',
                                            'Latitude', 'Longitude'),
                        target_col = 'LAW_CAT_CD')
knitr::kable(head(df_year), caption = "Head 6 Rows in Arrest Dataset for Spatial Analysis",
             row.names = F,font_size = 10)
```

Here is a brief structure of the cleaned data set.

```{r}
printStr(df_year)
```


## Pre-processing for Complaint Data
Our modification on Complaint Data set are similar to what we processed on Arrest Data set.

## Pre-processing for other Data Sets
No pre-processing is needed for other data sets.

## Next Stage
We have successfully constructed cleaned data sets for our actual analysis now.



<!--chapter:end:03-cleaning.Rmd-->


# Missing values

Placeholder


## Missing Data Analysis
### For shooting data (Historical):
### For shooting data (YTD):
### For Hata Crimes:
### For crime court summons (Historical):
### For crime court summons (YTD):
### For Motor Vehicle Collisions and Crahses (Historical):
### For arrest (Historical):
### For arrest (YTD):

<!--chapter:end:04-missing.Rmd-->


# Results

Placeholder


## Crime Arrest Analysis
### Overall Illustration on Map
### Time Analysis
### Spatial Analysis   
## Hate Crime Analysis

<!--chapter:end:05-results.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Interactive component

## Overview of Arrests Data by Time
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title></title>
        <script src="https://d3js.org/d3.v6.js"></script>
         <link rel="stylesheet" href="scripts/interactve.css">
       
    </head>
    <body>
    <p id="format1" >Total Arrests in History</p>
    <svg width="600" height="450" id="svg3">
    </svg>
    <p id="format1" >Arrests by Categories in 2021</p>
    <label>Select a crime category:</label>
    <select id="CrimeCategory"></select>
    <svg  width="600" height="450"  id="crimeByCategory"></svg> 
    <script type="text/javascript" src="scripts/totalCrime.js"> </script>
    <script type="text/javascript"  src="scripts/crimeByCategory.js"> </script>
    </body>
</html>

<!--chapter:end:06-interactive.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Conclusion


<!--chapter:end:07-conclusion.Rmd-->

